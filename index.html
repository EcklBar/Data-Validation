<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Apache Kafka: Complete Data Engineering Notebook</title>
    <style>
        :root {
            --primary-color: #2C3E50;
            --accent-color: #E67E22;
            --bg-color: #Fdfdfd;
            --sidebar-width: 260px;
            --text-color: #333;
            --code-bg: #f4f4f4;
            --border-color: #ddd;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--bg-color);
            margin: 0;
            display: flex;
        }

        /* Sidebar Navigation */
        nav {
            width: var(--sidebar-width);
            background: #f8f9fa;
            height: 100vh;
            position: fixed;
            padding: 20px;
            border-right: 1px solid var(--border-color);
            overflow-y: auto;
            z-index: 100;
        }

        nav h3 {
            color: var(--primary-color);
            margin-top: 0;
            border-bottom: 2px solid var(--accent-color);
            padding-bottom: 10px;
        }

        nav ul {
            list-style: none;
            padding: 0;
        }

        nav ul li {
            margin-bottom: 12px;
        }

        nav a {
            text-decoration: none;
            color: #555;
            font-weight: 500;
            font-size: 0.95rem;
            transition: color 0.2s;
            display: block;
        }

        nav a:hover {
            color: var(--accent-color);
            padding-left: 5px;
        }

        /* Main Content */
        main {
            margin-left: var(--sidebar-width);
            padding: 40px 60px;
            max-width: 950px;
            width: 100%;
        }

        h1 {
            font-size: 2.5rem;
            color: var(--primary-color);
            border-bottom: 3px solid var(--accent-color);
            padding-bottom: 10px;
            margin-bottom: 30px;
        }

        h2 {
            color: var(--primary-color);
            margin-top: 50px;
            border-left: 6px solid var(--accent-color);
            padding-left: 15px;
            font-size: 1.8rem;
        }

        h3 {
            color: #2980b9;
            margin-top: 30px;
            font-weight: 600;
        }

        h4 {
            color: #444;
            margin-bottom: 5px;
            text-transform: uppercase;
            font-size: 0.9rem;
            letter-spacing: 1px;
        }

        /* Notebook Elements */
        .note-block {
            background-color: #eefbfb;
            border-left: 4px solid #17a2b8;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .warning-block {
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 20px 0;
            border-radius: 4px;
        }

        .concept-card {
            background: white;
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 25px;
            margin-bottom: 25px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }

        .two-col-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 15px;
        }

        .api-table, .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.95rem;
        }

        th, td {
            border: 1px solid var(--border-color);
            padding: 12px;
            text-align: left;
        }

        th {
            background-color: var(--primary-color);
            color: white;
        }

        tr:nth-child(even) {
            background-color: #f8f9fa;
        }

        /* Visual Tags */
        .tag-blue { background: #3498db; color: white; padding: 2px 6px; border-radius: 4px; font-size: 0.8rem; }
        .tag-green { background: #27ae60; color: white; padding: 2px 6px; border-radius: 4px; font-size: 0.8rem; }
        
        .diagram-request {
            display: flex;
            align-items: center;
            justify-content: center;
            background: #fafafa;
            border: 2px dashed #ccc;
            color: #666;
            padding: 15px;
            margin: 15px 0;
            font-style: italic;
        }

    </style>
</head>
<body>

<nav>
    <h3>Naya College</h3>
    <ul>
        <li><a href="#intro">1. Introduction</a></li>
        <li><a href="#etl-vs-streaming">2. ETL vs. Streaming</a></li>
        <li><a href="#architecture">3. High-Level Architecture</a></li>
        <li><a href="#fundamentals">4. Fundamental Concepts</a></li>
        <li><a href="#brokers">4.1 Brokers & Cluster</a></li>
        <li><a href="#topics">4.2 Topics & Partitions</a></li>
        <li><a href="#replication">4.3 Replication</a></li>
        <li><a href="#producers">4.4 Producers</a></li>
        <li><a href="#consumers">4.5 Consumers & Groups</a></li>
        <li><a href="#zookeeper">4.6 Zookeeper</a></li>
        <li><a href="#apis">5. Core APIs</a></li>
        <li><a href="#use-cases">6. Use Cases & Industry</a></li>
    </ul>
</nav>

<main>
    <h1>Apache Kafka Notebook</h1>
    <p><em>Comprehensive guide based on Naya College Data Engineering curriculum. Covering architecture, fundamentals, and core APIs.</em></p>

    <section id="intro">
        <h2>1. What is Apache Kafka?</h2>
        <p>Apache Kafka is a distributed streaming platform based on the <strong>Pub-Sub (Publish-Subscribe)</strong> model.</p>
        <div class="note-block">
            <strong>Key takeaway:</strong> Kafka serves as a "central nervous system" for organization data, decoupling data providers from data consumers.
        </div>
            </section>

    <section id="etl-vs-streaming">
        <h2>2. Evolution: ETL vs. Streaming</h2>
        <div class="two-col-grid">
            <div class="concept-card">
                <h4>Old World (Traditional ETL)</h4>
                <ul>
                    <li>Batch processing (nightly/hourly).</li>
                    <li>Not real-time.</li>
                    <li>Complex point-to-point connections ("Spaghetti Architecture").</li>
                    <li>Hard to scale.</li>
                </ul>
            </div>
            <div class="concept-card">
                <h4>New World (Kafka Streaming)</h4>
                <ul>
                    <li>Real-time event capturing.</li>
                    <li>Fault tolerant & Parallel processing.</li>
                    <li>Decoupled Producers and Consumers.</li>
                    <li>Serves as the "Source of Truth" pipeline.</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="architecture">
        <h2>3. High-Level Architecture</h2>
        <p>Kafka creates a central streaming platform that ingests data from <strong>Producers</strong> and serves it to <strong>Consumers</strong>.</p>
        
        
        <h3>Data Flow Recap</h3>
        <ol>
            <li><strong>Producers:</strong> Write data into the Kafka cluster from multiple sources (Apps, DBs, Sensors).</li>
            <li><strong>Streaming Platform:</strong> Stores, processes, and manages the data streams.</li>
            <li><strong>Consumers:</strong> Read data for use cases (Monitoring, Analytics, Marketing).</li>
            <li><strong>Stream Processors:</strong> Consumers can also rewrite data back to Kafka (becoming Producers) to create derived streams.</li>
        </ol>
        
        <p><strong>Connectors:</strong> Specialized components (Source/Sink) that can capture events from systems (like RDBMS changes) and pull them into the pipeline without writing custom code.</p>
    </section>

    <section id="fundamentals">
        <h2>4. Fundamental Concepts</h2>
        <p>To operate Kafka, one must understand the hierarchy of its internal components.</p>

        <h3 id="brokers">4.1 Brokers & The Cluster</h3>
        <div class="concept-card">
            <ul>
                <li><strong>Broker:</strong> A single Kafka server.</li>
                <li><strong>Cluster:</strong> Composed of multiple brokers (typically 3 or more for resilience).</li>
                <li><strong>Connectivity:</strong> Connecting to one broker means you are connected to the entire cluster.</li>
                <li><strong>Resiliency:</strong> Each broker holds <em>some</em> data, but not all. If one fails, data is available on others via replication.</li>
            </ul>
        </div>

        <h3 id="topics">4.2 Topics, Partitions & Offsets</h3>
        
        <h4>The Topic</h4>
        <p>A <strong>Topic</strong> is a logical channel to which producers publish and consumers subscribe. It defines a stream of a particular type of data (e.g., "logs", "clicks", "transactions").</p>
        <ul>
            <li>Identified by a <strong>unique name</strong>.</li>
            <li><strong>Immutable:</strong> Once data is published, it cannot be changed.</li>
            <li><strong>Retention:</strong> Configurable (default is typically 1 week).</li>
        </ul>

        <h4>The Partition</h4>
        <p>Topics are split into <strong>Partitions</strong>. This is the main mechanism for parallelism and scalability.</p>
        
        
        <div class="warning-block">
            <strong>CRITICAL RULE:</strong> Data ordering/sequencing is guaranteed <strong>ONLY within a single partition</strong>. Sequencing is NOT guaranteed across different partitions in the same topic.
        </div>

        <ul style="background: #fff; padding: 20px; border: 1px solid #ddd;">
            <li><strong>Partition 0, 1, 2...:</strong> Messages are distributed among partitions.</li>
            <li><strong>Offset:</strong> An incremental ID assigned to each message within a partition. The first message is offset 0.</li>
            <li>There is no limitation on the number of partitions per topic.</li>
        </ul>

        <h3 id="replication">4.3 Replication Factor</h3>
        <p>To ensure High Availability (HA), Kafka copies partitions across multiple brokers.</p>
        
        
        <table class="api-table">
            <tr>
                <th>Component</th>
                <th>Role</th>
            </tr>
            <tr>
                <td><strong>Leader</strong></td>
                <td>The specific partition replica where all Reads and Writes occur. Only one broker can be a leader for a given partition.</td>
            </tr>
            <tr>
                <td><strong>Follower</strong></td>
                <td>Passive replicas that copy data from the leader. If the leader fails, a follower becomes the new leader.</td>
            </tr>
            <tr>
                <td><strong>Replication Factor</strong></td>
                <td>The number of copies (e.g., Factor 3 = 1 Leader + 2 Followers). Cannot exceed the number of available brokers.</td>
            </tr>
        </table>

        <h3 id="producers">4.4 Producers</h3>
        <p>Producers write data to topics. They only need to know the Topic Name and one Broker to connect.</p>
        <p><strong>Acknowledgments (Acks):</strong> Producers choose how durable they want the write to be:</p>
        <ul>
            <li><span class="tag-blue">acks = 0</span>: Fire and forget. Fast, but risky (data loss possible).</li>
            <li><span class="tag-blue">acks = 1</span>: Leader received the message. Default. Balanced.</li>
            <li><span class="tag-blue">acks = all</span>: Leader AND all replicas received the message. Slowest, but zero data loss.</li>
        </ul>

        <h3 id="consumers">4.5 Consumers & Consumer Groups</h3>
        <p>Consumers read data. To scale reading (e.g., if data is coming in at 1GB/sec but a consumer can only read 50MB/sec), we use <strong>Consumer Groups</strong>.</p>
        
        
        <div class="concept-card">
            <h4>Consumer Group Rules</h4>
            <ul>
                <li>A group contains one or more consumers working together.</li>
                <li><strong>The Golden Rule:</strong> Each partition is consumed by <strong>only one member</strong> of the group.</li>
                <li>This ensures no duplicate processing and maintains order per partition.</li>
                <li>If you have 4 partitions and 4 consumers, each reads 1. If you add a 5th consumer, it will sit idle.</li>
            </ul>
        </div>

        <h3 id="zookeeper">4.6 Zookeeper</h3>
        <p>Zookeeper is mandatory for running Kafka (though this is changing in very new versions, historically it is essential). It acts as the coordinator.</p>
        <ul>
            <li>Manages the list of Brokers (detects new or deleted brokers).</li>
            <li>Performs <strong>Leader Election</strong> for partitions.</li>
            <li>Stores topic configurations and quotas.</li>
        </ul>
    </section>

    <section id="apis">
        <h2>5. Core APIs & Distributions</h2>
        
        
        <table class="api-table">
            <thead>
                <tr>
                    <th>API Name</th>
                    <th>Function</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Producer API</strong></td>
                    <td>Allows applications to send data streams to topics in the Kafka cluster.</td>
                </tr>
                <tr>
                    <td><strong>Consumer API</strong></td>
                    <td>Allows applications to read data streams from topics.</td>
                </tr>
                <tr>
                    <td><strong>Streams API</strong></td>
                    <td>Allows for complex transformations (filter, map, aggregate) of data streams within Kafka.</td>
                </tr>
                <tr>
                    <td><strong>Connect API</strong></td>
                    <td><strong>Source:</strong> Reusable code to pull data from external systems (DBs) into Kafka.<br><strong>Sink:</strong> Reusable code to push data from Kafka to external systems (S3, HDFS).</td>
                </tr>
                <tr>
                    <td><strong>AdminClient API</strong></td>
                    <td>Manages Kafka objects (topics, brokers) programmatically.</td>
                </tr>
            </tbody>
        </table>

        <h3>Main Distributions</h3>
        <p>While Apache Kafka is open source, several vendors provide managed or enhanced versions:</p>
        <ul>
            <li><strong>Confluent:</strong> Founded by the creators of Kafka.</li>
            <li><strong>Cloudera / Hortonworks</strong></li>
            <li><strong>Cloud Managed:</strong> AWS Amazon Kinesis (alternative) / MSK, GCP Pub/Sub (alternative).</li>
        </ul>
    </section>

    <section id="use-cases">
        <h2>6. Real-World Use Cases</h2>
        <div class="two-col-grid">
            <div class="concept-card">
                <h4>Netflix</h4>
                <p>Uses Kafka for recommendation systems and saving "last stop point" on movies across devices.</p>
            </div>
            <div class="concept-card">
                <h4>PayPal</h4>
                <p>Real-time fraud detection and transaction consistency.</p>
            </div>
            <div class="concept-card">
                <h4>Uber</h4>
                <p>Matching riders and drivers in real-time. (Also created Kafka Streams).</p>
            </div>
            <div class="concept-card">
                <h4>Walmart</h4>
                <p>Handling billions of transactions/inventory updates daily.</p>
            </div>
        </div>
    </section>

</main>

</body>
</html>
